{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #may need numpy\n",
    "import pandas as pd #may need pandas\n",
    "import math #need for mathematical calculation\n",
    "from pprint import pprint #need for showing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the pureness of each subtree we need a measure. Typically, entropy is the way to measure the pureness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(probability, summed_probs):\n",
    "    return - (probability/summed_probs) * math.log(\n",
    "        probability/summed_probs, 2)\n",
    "\n",
    "def entropy_of_classes(class_1, class_2):\n",
    "    #entropy would be 0 if we only have 1 class in our group\n",
    "    if class_1 == 0 or class_2 == 0:\n",
    "        return 0\n",
    "    #otherwise, the sum of the probabilities of the class is the\n",
    "    #summed_probs and each class has its own probability\n",
    "    return (entropy(class_1, class_1 + class_2) + \n",
    "            entropy(class_2, class_1 + class_2))\n",
    "\n",
    "#now its time to calculate the whole entropy:\n",
    "def calculate_entropy(y_hat, y):\n",
    "    if len(y_hat) != len(y):\n",
    "        print('Output Error')\n",
    "        return None\n",
    "    \n",
    "    n = len(y)\n",
    "    s_true = 0\n",
    "    n_true = len(y[y_hat])\n",
    "    s_false = 0\n",
    "    n_false = len(y[~y_hat])\n",
    "    classes = set(y[y_hat])\n",
    "    for i in classes:\n",
    "        num_classes = sum(y[y_hat]==i)\n",
    "        e = (num_classes/n_true) * entropy_of_classes(\n",
    "            sum(y[y_hat] == i), sum(y[y_hat] != i))\n",
    "        s_true += e\n",
    "\n",
    "    classes = set(y[~y_hat])\n",
    "    for i in classes:\n",
    "        num_classes = sum(y[~y_hat] == i)\n",
    "        e = (num_classes/n_false) * entropy_of_classes(\n",
    "            sum(y[~y_hat] == i), sum(y[~y_hat] != i))\n",
    "        s_false += e\n",
    "    \n",
    "    s = n_true / n * s_true + n_false / n * s_false\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_tree_classifier(object):\n",
    "    def __init__(self, max_depth):\n",
    "        self.depth = 0 #we want to count the depth we are going through\n",
    "        self.max_depth = max_depth #this values has been gotten as input\n",
    "    \n",
    "####*******************************************************************************#############   \n",
    "    \n",
    "    def find_best_split_of_all(self, x, y):\n",
    "        feature = None\n",
    "        n = len(y)\n",
    "        min_entropy = 1\n",
    "        max_val = None\n",
    "        \n",
    "        for bestFeature, feature in enumerate(x.T):\n",
    "            entropy = 10    \n",
    "            for value in set(feature):\n",
    "                y_hat = feature < value\n",
    "                current_entropy = calculate_entropy(y_hat, y)  # get entropy of this split\n",
    "                if current_entropy <= entropy:\n",
    "                    entropy = current_entropy\n",
    "                    curr_maxVal = value\n",
    "            \n",
    "            if entropy == 0:\n",
    "                return bestFeature, curr_maxVal, entropy\n",
    "            \n",
    "            elif entropy <= min_entropy:\n",
    "                min_entropy = entropy\n",
    "                best_feature = bestFeature\n",
    "                max_val = curr_maxVal\n",
    "                \n",
    "        return best_feature, max_val, min_entropy\n",
    "\n",
    "####*******************************************************************************#############   \n",
    "    \n",
    "    #this function is solely for fitting the data to a model to find the best\n",
    "    #hopothysis among existing hopothysises\n",
    "    def fit(self, x, y, depth = 0):\n",
    "        dict_of_nodes = {} #we need a dictionary to save the partitions\n",
    "        depth=0 #keep track of depth we go through\n",
    "\n",
    "        #when dictionary is null, then we do not need to go forward\n",
    "        #so we return None\n",
    "        if dict_of_nodes is None:\n",
    "            return None\n",
    "        \n",
    "        #When we have no data for a single group, we cannot go forward\n",
    "        elif len(y) == 0:\n",
    "            return None\n",
    "        \n",
    "        #when all y we have are from the same group, we return its value\n",
    "        elif all(i == y[0] for i in y):\n",
    "            return {'value': y[0]}\n",
    "        \n",
    "        #if depth is reached its maximum, we stop the progression\n",
    "        elif depth >= self.max_depth:   \n",
    "            return None\n",
    "        \n",
    "        # If none of the above, we resume the ID3 algorithm\n",
    "        else:   \n",
    "            #we split the data based on its information gain:\n",
    "            feature, max_val, entropy = self.find_best_split_of_all(x, y)\n",
    "            \n",
    "            #we separate data of the class which are less than the max_value\n",
    "            #on the left subtree\n",
    "            true_values = x[:, feature] < max_val #gives us [True or False] array\n",
    "            y_left = y[true_values] #converts the [True or False] array into [1 or 0]\n",
    "\n",
    "            #the same as above but for larger than the max_value goes to the right hand side\n",
    "            true_values = x[:, feature] >= max_val\n",
    "            y_right = y[true_values]\n",
    "            \n",
    "            dict_of_nodes = {\n",
    "                'feature': iris.feature_names[feature],\n",
    "                'index_feature':feature, \n",
    "                'max_value':max_val,\n",
    "                'value': np.round(np.mean(y))\n",
    "            }\n",
    "            \n",
    "            # recursively we generate tree for the left hand side\n",
    "            dict_of_nodes['left'] = self.fit(x[x[:, feature] < max_val], y_left, depth+1)\n",
    "            \n",
    "            # recursively we generate tree for the right hand side\n",
    "            dict_of_nodes['right'] = self.fit(x[x[:, feature] >= max_val], y_right, depth+1)  \n",
    "            \n",
    "            self.depth += 1 #increasing the depth after coming out of the recursion\n",
    "            self.trees = dict_of_nodes  \n",
    "            return dict_of_nodes\n",
    "\n",
    "####*******************************************************************************#############   \n",
    "        \n",
    "    def predict(self, x):\n",
    "        results = np.zeros(len(x))        \n",
    "        for i, c in enumerate(x):\n",
    "            cur_layer = self.trees\n",
    "            while cur_layer.get('max_value'):\n",
    "                if c[cur_layer['index_feature']] < cur_layer['max_value']:\n",
    "                    cur_layer = cur_layer['left']\n",
    "                else:\n",
    "                    cur_layer = cur_layer['right']\n",
    "            else:\n",
    "                results[i] = cur_layer.get('value')\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x) #not much data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[:120]\n",
    "y_train = y[:120]\n",
    "x_test = x[120:]\n",
    "y_test = y[120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 1., 2., 2., 1., 1., 2., 1., 2., 2., 2., 1., 2., 2., 2.,\n",
       "       2., 1., 2., 2., 2., 2., 2., 2., 2., 1., 2., 2., 2.])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = decision_tree_classifier(max_depth=7)\n",
    "vision = clf.fit(x_train, y_train)\n",
    "clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing With SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(x_train, y_train)\n",
    "clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets See how it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature': 'petal width (cm)',\n",
      " 'index_feature': 3,\n",
      " 'left': {'value': 0},\n",
      " 'max_value': 1.0,\n",
      " 'right': {'feature': 'petal width (cm)',\n",
      "           'index_feature': 3,\n",
      "           'left': {'feature': 'petal length (cm)',\n",
      "                    'index_feature': 2,\n",
      "                    'left': {'value': 1},\n",
      "                    'max_value': 5.0,\n",
      "                    'right': {'feature': 'sepal width (cm)',\n",
      "                              'index_feature': 1,\n",
      "                              'left': {'value': 2},\n",
      "                              'max_value': 2.7,\n",
      "                              'right': {'value': 1},\n",
      "                              'value': 2.0},\n",
      "                    'value': 1.0},\n",
      "           'max_value': 1.7,\n",
      "           'right': {'feature': 'petal length (cm)',\n",
      "                     'index_feature': 2,\n",
      "                     'left': {'feature': 'sepal length (cm)',\n",
      "                              'index_feature': 0,\n",
      "                              'left': {'value': 2},\n",
      "                              'max_value': 5.9,\n",
      "                              'right': {'value': 1},\n",
      "                              'value': 2.0},\n",
      "                     'max_value': 5.1,\n",
      "                     'right': {'value': 2},\n",
      "                     'value': 2.0},\n",
      "           'value': 1.0},\n",
      " 'value': 1.0}\n"
     ]
    }
   ],
   "source": [
    "pprint(vision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
