{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def network_initialization(num_input, num_classes, x_train):\n",
    "    #number of classes is 10 --> 0-9\n",
    "    #number of input features are 28 * 28\n",
    "    #xTw + b ==> x = [1, number of features][number of features, number of class]\n",
    "    # ==> [1, number of classes] <== b\n",
    "    w = np.random.rand(num_input, num_classes)\n",
    "    b = np.random.rand(1, num_classes)\n",
    "    param = {\"weight\": w, \"bias\": b}\n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(y_hat, y):\n",
    "    eps = np.finfo(float).eps\n",
    "    predictions = np.clip(y_hat, eps, 1 - eps)\n",
    "    predictions /= np.sum(predictions)[np.newaxis]\n",
    "    rows = y.shape[0]\n",
    "    vsota = np.sum(y * np.log(predictions))\n",
    "    value = (-1.0 / rows * vsota)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot(y):\n",
    "    m = y.shape[0]\n",
    "    OH = scipy.sparse.csr_matrix((np.ones(m), (y, np.array(range(m)))))\n",
    "    OH = np.array(OH.todense()).T\n",
    "    return OH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_preparation(x_train, y_train, y_test):\n",
    "    hyperparam = {}\n",
    "    hyperparam[\"num_epochs\"] = 100\n",
    "    hyperparam[\"batch_size\"] = 64\n",
    "    hyperparam[\"num_samples\"] = x_train.shape[0]\n",
    "    hyperparam[\"mini_BGD\"] = False\n",
    "    hyperparam[\"num_batch\"] = int(num_samples / batch_size)\n",
    "    hyperparam[\"learning_rate\"] = 0.001\n",
    "    last_batch = num_samples % batch_size\n",
    "\n",
    "    y_train = oneHot(y_train)\n",
    "    y_test = oneHot(y_test)\n",
    "\n",
    "    loss_epoch_report = 0\n",
    "    loss_batch_report = 0\n",
    "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1] * x_train.shape[2]))\n",
    "    x_test = x_test.reshape((x_test.shape[0], x_test.shape[1] * x_test.shape[2]))\n",
    "    return x_train, y_train, y_test, hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import log_loss\n",
    "# from scipy.special import softmax\n",
    "\n",
    "\n",
    "param = network_initialization(784, 10, x_train)\n",
    "def fit_SGD(x_train, y_train, y_test, hyperparam, param):\n",
    "    loss_epoch_report = 0\n",
    "    accuracy = 0\n",
    "    learning_rate = hyperparam[\"learning_rate\"]\n",
    "    for epoch in range(hyperparam[\"num_epochs\"]):\n",
    "        if epoch % 20 == 0:\n",
    "            learning_rate /= 2\n",
    "        shuffling = np.arange(hyperparam[\"num_samples\"])\n",
    "        np.random.seed(0)\n",
    "        np.random.RandomState(seed=42).shuffle(shuffling)\n",
    "        x_epoch = x_train[shuffling]\n",
    "        y_epoch = y_train[shuffling]\n",
    "\n",
    "        #calculating xTw + b\n",
    "        mat_mul = np.dot(x_epoch, param[\"weight\"]) + param[\"bias\"]\n",
    "\n",
    "        #calculating softmax of xTw+b\n",
    "        mat_mul = mat_mul / np.sum(mat_mul, axis = 1)[:, np.newaxis]\n",
    "        sm = np.exp(mat_mul) / np.sum(np.exp(mat_mul), axis = 1)[:, np.newaxis]\n",
    "\n",
    "        #softmax result with probabilities to 0s and 1s\n",
    "        softmax_out = np.zeros_like(sm)\n",
    "        softmax_out[np.arange(len(sm)), sm.argmax(1)] = 1\n",
    "\n",
    "        #softmax class output\n",
    "        y_hat = np.argmax(sm, axis = 1)[:, np.newaxis]\n",
    "\n",
    "        #class output of true labels\n",
    "        y_label = np.argmax(y_epoch, axis = 1)[:, np.newaxis]\n",
    "\n",
    "        #calculating accuracy of the model\n",
    "        accuracy = (y_hat == y_label).all(axis = 1).mean()\n",
    "\n",
    "        #calling logloss function\n",
    "        loss_epoch_report = logloss(y_epoch, softmax_out)\n",
    "\n",
    "        #calculating gradient of weight and bias\n",
    "        weight_grad = np.dot(x_epoch.T, softmax_out - y_epoch)\n",
    "        bias_grad = -(softmax_out - y_epoch)\n",
    "\n",
    "        #updating parameters\n",
    "        param[\"weight\"] =  param[\"weight\"] - learning_rate * weight_grad\n",
    "        param[\"bias\"] = param[\"bias\"] - (learning_rate * bias_grad)\n",
    "\n",
    "        #report so far\n",
    "        print(\"accuracy is: \", accuracy)\n",
    "        print(\"loss for epoch \", epoch, \" is: \", loss_epoch_report)\n",
    "        loss_epoch_report = 0\n",
    "        accuracy = 0\n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape x_train\n",
    "def fit_mini_BGD(param, hyperparam, x_train, y_train):\n",
    "    batch_size = hyperparam[\"batch_size\"]\n",
    "    learning_rate = hyperparam[\"learning_rate\"]\n",
    "    num_samples = hyperparam[\"num_samples\"]\n",
    "    num_batch = hyperparam[\"num_batch\"]\n",
    "    last_batch = num_samples % batch_size\n",
    "    loss_epoch_report = 0\n",
    "    loss_batch_report = 0\n",
    "    batch_gradient_descent = hyperparam[\"mini_BGD\"]\n",
    "    \n",
    "    for epoch in range(hyperparam[\"num_epochs\"]):\n",
    "        shuffling = np.arange(num_samples)\n",
    "        np.random.shuffle(shuffling)\n",
    "        \n",
    "        for batch in range(num_batch):\n",
    "            x_batch = x_train[shuffling][\n",
    "                batch * batch_size: (batch + 1) * batch_size]\n",
    "            y_batch = y_train[shuffling][\n",
    "                batch * batch_size: (batch + 1) * batch_size]\n",
    "            \n",
    "            #mini batch calculations\n",
    "            dw, db, batch_loss, acc = mini_BGD(\n",
    "                param, x_batch, y_batch, batch_size)\n",
    "            loss_batch_report += (batch_loss * (batch + 1)/(batch + 2))\n",
    "            loss_epoch_report += (batch_loss * (batch + 1)/(batch + 2))\n",
    "            param[\"weight\"] = param[\"weight\"] - learning_rate * dw\n",
    "            param[\"bias\"] = param[\"bias\"] - learning_rate * db\n",
    "            if batch % 50 == 0:\n",
    "                print(\"loss for epoch \", epoch, \" and batch \", batch, \" is: \",\n",
    "                     loss_batch_report/((batch+1) * batch_size))\n",
    "                print(\"and accuracy is: \", acc)\n",
    "                loss_batch_report = 0\n",
    "\n",
    "        print(\"loss for epoch \", epoch, \" is: \", loss_epoch_report)\n",
    "        loss_epoch_report = 0\n",
    "    \n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_BGD(param, x_batch, y_batch, batch_size):\n",
    "    loss = 0\n",
    "    \n",
    "    #calculating xTw + b\n",
    "    mat_mul = np.dot(x_batch, param[\"weight\"])\n",
    "\n",
    "    #calculating softmax of xTw+b\n",
    "    mat_mul = mat_mul / np.sum(mat_mul, axis = 1)[:, np.newaxis]\n",
    "    sm = np.exp(mat_mul) / np.sum(np.exp(mat_mul), axis = 1)[:, np.newaxis]\n",
    "\n",
    "    #softmax result with probabilities to 0s and 1s\n",
    "    softmax_out = np.zeros_like(sm)\n",
    "    softmax_out[np.arange(len(sm)), sm.argmax(1)] = 1\n",
    "\n",
    "    #softmax class output\n",
    "    y_hat = np.argmax(sm, axis = 1)[:, np.newaxis]\n",
    "\n",
    "    #class output of true labels\n",
    "    y_label = np.argmax(y_batch, axis = 1)[:, np.newaxis]\n",
    "\n",
    "    #calculating accuracy of the model\n",
    "    accuracy = (y_hat == y_label).all(axis = 1).mean()\n",
    "\n",
    "    #calling logloss function\n",
    "    loss = logloss(y_batch, softmax_out)\n",
    "\n",
    "    #calculating gradient of weight and bias\n",
    "    weight_grad = np.dot(x_batch.T, softmax_out - y_batch)\n",
    "    bias_grad = -(softmax_out - y_epoch)\n",
    "    \n",
    "    return weight_grad, bias_grad, loss, accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(x_test, y_test, param):\n",
    "    #calculating xTw + b\n",
    "    mat_mul = np.dot(x_test, param[\"weight\"])\n",
    "\n",
    "    #calculating softmax of xTw+b\n",
    "    mat_mul = mat_mul / np.sum(mat_mul, axis = 1)[:, np.newaxis]\n",
    "    sm = np.exp(mat_mul) / np.sum(np.exp(mat_mul), axis = 1)[:, np.newaxis]    \n",
    "    \n",
    "    #softmax class output\n",
    "    y_hat = np.argmax(sm, axis = 1)[:, np.newaxis]\n",
    "\n",
    "    #class output of true labels\n",
    "    y_label = np.argmax(y_test, axis = 1)[:, np.newaxis]\n",
    "\n",
    "    #calculating accuracy of the model\n",
    "    accuracy = (y_hat == y_label).all(axis = 1).mean()\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  0.116\n",
      "loss for epoch  0  is:  42.86468943718382\n",
      "accuracy is:  0.37803333333333333\n",
      "loss for epoch  1  is:  33.42005079412214\n",
      "accuracy is:  0.21013333333333334\n",
      "loss for epoch  2  is:  39.47178019815491\n",
      "accuracy is:  0.4733\n",
      "loss for epoch  3  is:  29.986292081252262\n",
      "accuracy is:  0.3568\n",
      "loss for epoch  4  is:  34.185377701084384\n",
      "accuracy is:  0.47153333333333336\n",
      "loss for epoch  5  is:  30.049969202239687\n",
      "accuracy is:  0.39935\n",
      "loss for epoch  6  is:  32.651720249377455\n",
      "accuracy is:  0.39895\n",
      "loss for epoch  7  is:  32.66613771073311\n",
      "accuracy is:  0.5555333333333333\n",
      "loss for epoch  8  is:  27.022302317553837\n",
      "accuracy is:  0.5950166666666666\n",
      "loss for epoch  9  is:  25.59917873624021\n",
      "accuracy is:  0.691\n",
      "loss for epoch  10  is:  22.139588738441436\n",
      "accuracy is:  0.6867666666666666\n",
      "loss for epoch  11  is:  22.2921735377887\n",
      "accuracy is:  0.6906\n",
      "loss for epoch  12  is:  22.154006199797095\n",
      "accuracy is:  0.7585833333333334\n",
      "loss for epoch  13  is:  19.703638496893596\n",
      "accuracy is:  0.7714666666666666\n",
      "loss for epoch  14  is:  19.23927609573047\n",
      "accuracy is:  0.7725833333333333\n",
      "loss for epoch  15  is:  19.19902734944596\n",
      "accuracy is:  0.78445\n",
      "loss for epoch  16  is:  18.77130932922845\n",
      "accuracy is:  0.7918166666666666\n",
      "loss for epoch  17  is:  18.505787749261945\n",
      "accuracy is:  0.8055333333333333\n",
      "loss for epoch  18  is:  18.01138897027455\n",
      "accuracy is:  0.8148666666666666\n",
      "loss for epoch  19  is:  17.674981538642793\n",
      "accuracy is:  0.8313\n",
      "loss for epoch  20  is:  17.08266416794831\n",
      "accuracy is:  0.86685\n",
      "loss for epoch  21  is:  15.801312289965184\n",
      "accuracy is:  0.8690833333333333\n",
      "loss for epoch  22  is:  15.72081479739616\n",
      "accuracy is:  0.8702\n",
      "loss for epoch  23  is:  15.680566051111652\n",
      "accuracy is:  0.8714166666666666\n",
      "loss for epoch  24  is:  15.636712939488218\n",
      "accuracy is:  0.8725833333333334\n",
      "loss for epoch  25  is:  15.594662010534247\n",
      "accuracy is:  0.8735666666666667\n",
      "loss for epoch  26  is:  15.559219084701619\n",
      "accuracy is:  0.8744\n",
      "loss for epoch  27  is:  15.529182706877357\n",
      "accuracy is:  0.87525\n",
      "loss for epoch  28  is:  15.498545601496605\n",
      "accuracy is:  0.87605\n",
      "loss for epoch  29  is:  15.469710678785313\n",
      "accuracy is:  0.8768\n",
      "loss for epoch  30  is:  15.442677938743476\n",
      "accuracy is:  0.87765\n",
      "loss for epoch  31  is:  15.412040833362719\n",
      "accuracy is:  0.8783833333333333\n",
      "loss for epoch  32  is:  15.385608820877364\n",
      "accuracy is:  0.87935\n",
      "loss for epoch  33  is:  15.350766622601219\n",
      "accuracy is:  0.8803\n",
      "loss for epoch  34  is:  15.316525151881557\n",
      "accuracy is:  0.88105\n",
      "loss for epoch  35  is:  15.289492411839724\n",
      "accuracy is:  0.8817166666666667\n",
      "loss for epoch  36  is:  15.265463309580305\n",
      "accuracy is:  0.8823166666666666\n",
      "loss for epoch  37  is:  15.243837117546844\n",
      "accuracy is:  0.8828833333333334\n",
      "loss for epoch  38  is:  15.223412380626343\n",
      "accuracy is:  0.8833\n",
      "loss for epoch  39  is:  15.208394191714216\n",
      "accuracy is:  0.88385\n",
      "loss for epoch  40  is:  15.188570182350196\n",
      "accuracy is:  0.8841333333333333\n",
      "loss for epoch  41  is:  15.178357813889944\n",
      "accuracy is:  0.8844833333333333\n",
      "loss for epoch  42  is:  15.165742535203755\n",
      "accuracy is:  0.8847166666666667\n",
      "loss for epoch  43  is:  15.157332349412963\n",
      "accuracy is:  0.8849666666666667\n",
      "loss for epoch  44  is:  15.148321436065686\n",
      "accuracy is:  0.88535\n",
      "loss for epoch  45  is:  15.134504702266527\n",
      "accuracy is:  0.8855166666666666\n",
      "loss for epoch  46  is:  15.12849742670167\n",
      "accuracy is:  0.88595\n",
      "loss for epoch  47  is:  15.112878510233056\n",
      "accuracy is:  0.8862166666666667\n",
      "loss for epoch  48  is:  15.103266869329287\n",
      "accuracy is:  0.8863833333333333\n",
      "loss for epoch  49  is:  15.09725959376444\n",
      "accuracy is:  0.8869\n",
      "loss for epoch  50  is:  15.07863703951339\n",
      "accuracy is:  0.88735\n",
      "loss for epoch  51  is:  15.062417395488284\n",
      "accuracy is:  0.8874166666666666\n",
      "loss for epoch  52  is:  15.060014485262343\n",
      "accuracy is:  0.8876333333333334\n",
      "loss for epoch  53  is:  15.052205027028036\n",
      "accuracy is:  0.8878166666666667\n",
      "loss for epoch  54  is:  15.045597023906696\n",
      "accuracy is:  0.8879166666666667\n",
      "loss for epoch  55  is:  15.041992658567786\n",
      "accuracy is:  0.8880333333333333\n",
      "loss for epoch  56  is:  15.037787565672392\n",
      "accuracy is:  0.8881833333333333\n",
      "loss for epoch  57  is:  15.032381017664024\n",
      "accuracy is:  0.8884666666666666\n",
      "loss for epoch  58  is:  15.022168649203778\n",
      "accuracy is:  0.8886\n",
      "loss for epoch  59  is:  15.017362828751894\n",
      "accuracy is:  0.8888666666666667\n",
      "loss for epoch  60  is:  15.007751187848122\n",
      "accuracy is:  0.8889\n",
      "loss for epoch  61  is:  15.006549732735154\n",
      "accuracy is:  0.88895\n",
      "loss for epoch  62  is:  15.0047475500657\n",
      "accuracy is:  0.8890666666666667\n",
      "loss for epoch  63  is:  15.000542457170305\n",
      "accuracy is:  0.8891\n",
      "loss for epoch  64  is:  14.999341002057333\n",
      "accuracy is:  0.8891666666666667\n",
      "loss for epoch  65  is:  14.996938091831389\n",
      "accuracy is:  0.8892833333333333\n",
      "loss for epoch  66  is:  14.992732998935994\n",
      "accuracy is:  0.8893166666666666\n",
      "loss for epoch  67  is:  14.991531543823024\n",
      "accuracy is:  0.8895166666666666\n",
      "loss for epoch  68  is:  14.984322813145202\n",
      "accuracy is:  0.8895333333333333\n",
      "loss for epoch  69  is:  14.983722085588715\n",
      "accuracy is:  0.8896\n",
      "loss for epoch  70  is:  14.981319175362778\n",
      "accuracy is:  0.88965\n",
      "loss for epoch  71  is:  14.97951699269332\n",
      "accuracy is:  0.8897166666666667\n",
      "loss for epoch  72  is:  14.97711408246738\n",
      "accuracy is:  0.88975\n",
      "loss for epoch  73  is:  14.97591262735441\n",
      "accuracy is:  0.8899\n",
      "loss for epoch  74  is:  14.970506079346043\n",
      "accuracy is:  0.88995\n",
      "loss for epoch  75  is:  14.968703896676585\n",
      "accuracy is:  0.8901166666666667\n",
      "loss for epoch  76  is:  14.96269662111173\n",
      "accuracy is:  0.8901833333333333\n",
      "loss for epoch  77  is:  14.960293710885788\n",
      "accuracy is:  0.8902833333333333\n",
      "loss for epoch  78  is:  14.956689345546877\n",
      "accuracy is:  0.8903\n",
      "loss for epoch  79  is:  14.956088617990389\n",
      "accuracy is:  0.8904166666666666\n",
      "loss for epoch  80  is:  14.951883525094999\n",
      "accuracy is:  0.89045\n",
      "loss for epoch  81  is:  14.95068206998203\n",
      "accuracy is:  0.8905\n",
      "loss for epoch  82  is:  14.948879887312573\n",
      "accuracy is:  0.8905333333333333\n",
      "loss for epoch  83  is:  14.947678432199602\n",
      "accuracy is:  0.8905666666666666\n",
      "loss for epoch  84  is:  14.946476977086633\n",
      "accuracy is:  0.8907166666666667\n",
      "loss for epoch  85  is:  14.941070429078264\n",
      "accuracy is:  0.89075\n",
      "loss for epoch  86  is:  14.939868973965295\n",
      "accuracy is:  0.8908166666666667\n",
      "loss for epoch  87  is:  14.937466063739352\n",
      "accuracy is:  0.8908666666666667\n",
      "loss for epoch  88  is:  14.935663881069896\n",
      "accuracy is:  0.8909333333333334\n",
      "loss for epoch  89  is:  14.933260970843955\n",
      "accuracy is:  0.89095\n",
      "loss for epoch  90  is:  14.93266024328747\n",
      "accuracy is:  0.8910333333333333\n",
      "loss for epoch  91  is:  14.929656605505043\n",
      "accuracy is:  0.89105\n",
      "loss for epoch  92  is:  14.929055877948556\n",
      "accuracy is:  0.8911166666666667\n",
      "loss for epoch  93  is:  14.926652967722617\n",
      "accuracy is:  0.8912\n",
      "loss for epoch  94  is:  14.923649329940192\n",
      "accuracy is:  0.8912833333333333\n",
      "loss for epoch  95  is:  14.92064569215776\n",
      "accuracy is:  0.8913\n",
      "loss for epoch  96  is:  14.920044964601276\n",
      "accuracy is:  0.8913333333333333\n",
      "loss for epoch  97  is:  14.918843509488303\n",
      "accuracy is:  0.8914\n",
      "loss for epoch  98  is:  14.916440599262364\n",
      "accuracy is:  0.8913833333333333\n",
      "loss for epoch  99  is:  14.917041326818849\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = load_data()\n",
    "param = network_initialization(784, 10, x_train)\n",
    "x_train, y_train, y_test, hyperparam = test_preparation(\n",
    "    x_train, y_train, y_test)\n",
    "if hyperparam[\"mini_BGD\"] = True:\n",
    "    param = fit_mini_BGD(param, hyperparam, x_train, y_train)\n",
    "else:\n",
    "    param = fit_SGD(x_train, y_train, y_test, hyperparam, param)\n",
    "\n",
    "testing(x_test, y_test, param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (784, 10)\n",
      "0.8979\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "#     z -= np.max(z)\n",
    "    sm = (np.exp(z) / np.sum(np.exp(z),axis=1))\n",
    "    result = sm.reshape((len(z),1))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = x_train[0].reshape((x_train.shape[1] * x_train.shape[2], 1))\n",
    "# print(a.shape)\n",
    "# print(np.dot(a.T, param[\"weight\"]))\n",
    "# print(y_train[0])\n",
    "# print(oneHot(y_train)[0])\n",
    "# print(y_train.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1347,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/sepehr/.local/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "print(x_train.shape, y_train.shape)\n",
    "y_label = np.argmax(y_train, axis = 1)[:, np.newaxis]\n",
    "clf = LogisticRegression(random_state=0).fit(x_train, y_label)\n",
    "clf.predict(x_train[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9324333333333333"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_train, y_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
